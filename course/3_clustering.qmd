---
title: "Clustering concepts and correlation"
---

# Clustering

*Clustering* is a technique used to group similar objects or data points together based on their characteristics or features. For example, clustering can be applied to gene expression data to identify groups of genes that behave similarly under different experimental conditions. These clusters might ultimately inform cell types or subtypes. There are several different clustering techniques, including hierarchical or K-means clustering. It is important to understand the limitations or assumptions of a clustering algorithm when applying it to your data.

## K-means clustering

K-means clustering is a popular unsupervised machine learning algorithm used for partitioning a dataset into a predetermined number of clusters. The goal of k-means clustering is to group data points into clusters such that data points within the same cluster are more similar to each other than to those in other clusters. The algorithm works iteratively to assign each data point to the nearest cluster centroid (center point of a cluster) and then update the centroid based on the mean of all data points assigned to that cluster. This process continues until the centroids no longer change significantly, or a specified number of iterations is reached.

K-means has some limitations, such as sensitivity to the initial random selection of centroids and the need to specify the number of clusters beforehand. Additionally, k-means may not perform well on datasets with non-spherical or irregularly shaped clusters.

# Dimension Reduction

Dimension reduction is a crucial step in analyzing high-dimensional data, such as gene expression data, where the number of features (genes) is large compared to the number of samples (experimental conditions). Dimension reduction techniques aim to simplify the data while preserving its essential structure, simplifying hundreds or thousands of features into a two-dimensional space. For clustering cell types or samples, this approach enables the identification of which genes are the most different across groups or clusters.

## Principal Component Analysis (PCA)

PCA is a widely used dimension reduction technique that transforms high-dimensional data into a lower-dimensional representation by identifying the principal components that capture the maximum variance in the data. These principal components are orthogonal to each other and can be used to visualize the data in lower dimensions.

# Correlation

Correlation measures the strength and direction of the relationship between two variables. In bioinformatics, correlation analysis is often used to explore relationships between gene expression levels across different samples or experimental conditions.

## Spearman vs. Pearson Correlation

- **Pearson Correlation**: Measures the linear relationship between two variables. It assumes that the variables are normally distributed and have a linear relationship.
- **Spearman Correlation**: Measures the monotonic relationship between two variables. It does not assume linearity and is more robust to outliers and non-normal distributions.

## Example Code

```R
# Load required libraries
library(ggpubr)

# Example dataframe
df <- data.frame(
  Gene1 = c(1, 2, 3, 4, 5),
  Gene2 = c(5, 4, 3, 2, 1),
  Gene3 = c(2, 3, 4, 5, 6)
)

# Perform PCA
pca_result <- prcomp(df)

# Plot PCA
plot(pca_result$x[,1], pca_result$x[,2], 
     xlab = "PC1", ylab = "PC2", 
     main = "PCA Plot")

# Perform clustering
# Example clustering algorithm: k-means
kmeans_result <- kmeans(df, centers = 2)

# Plot clustering
plot(df, col = kmeans_result$cluster, 
     main = "Clustering Plot")

# Add correlation statistics to a plot
# Example plot
ggscatter(df, x = "Gene1", y = "Gene2", 
          add = "reg.line", 
          cor.coef = TRUE, 
          cor.method = "spearman", 
          cor.coeff.args = list(method = "spearman"))


